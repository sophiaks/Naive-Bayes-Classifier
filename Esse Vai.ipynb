{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Projeto 2 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Amanda Rosa do Carmo\n",
    "\n",
    "Nome: Beatriz Cabral\n",
    "\n",
    "Nome: Sophia Kerber Shigueoka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introdu√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo desse projeto √© criar um classificador capaz de analisar como a audi√™ncia de ‚Äú13 reasons why‚Äù, uma s√©rie de televis√£o pol√™mica, est√° reagindo. Para tal fim, ser√° feita uma an√°lise da probabilidade de um tweet ser relevante dada as palavras do seu conte√∫do, utilizando o princ√≠pio do algoritimo de Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Desenvolvimento e metodologia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   A fim de simplificar a explica√ß√£o do processo de desenvolvimento do projeto, ele ser√° dividido em  X etapas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETAPA 1 - Preparando o ambiente no jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa etapa, ser√£o baixadas e importadas todas as bibliotecas relevantes para o c√≥digo, bem como implementadas todas as fun√ß√µes a serem utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Importando as bibliotecas\n",
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\n",
    "    \"\"\"\n",
    "    punctuation = '[!\\-.:?;‚Ä¢,]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### ETAPA 2 - Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***@KerberSophie***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui ser√° feita a autentica√ß√£o no twitter, a partir de um c√≥digo obtido no pr√≥prio site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autentica√ß√£o do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @KerberSophie\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. N√£o modificar\n",
    "# auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "# auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETAPA 3 - Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, iremos fazer a coleta dos dados, nesse caso de tweets, a partir da keyword ‚Äú13 reasons why‚Äù escolhida. Feita a coleta, os dados foram salvos dentro de uma planilha no excel. Para importar as mensagens do Twitter, foi necess√°rio o uso da biblioteca Tweepy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantidade m√≠nima de mensagens capturadas:\n",
    "Escolhemos 1480 a partir de um m√©todo emp√≠rico. Quando testamos com 1000 n√£o conseguimos tweets suficientes, e chegamos\n",
    "a conclus√£o de que o problema era proveniente do set(), que diminu√≠a a quantidade de tweets baixados. Assim, decidiu-se\n",
    "aumentar a quantidade de tweets para 1500, j√° que com 1000 ficaram falatando 360 tweets. Com 1500, ficamos com 20 tweets a mais.\n",
    "como eram somente 20 tweets, imaginamos que poucos deles seriam retweets, ent√£o tiramos exatamente 20 tweets dos 1500.\n",
    "Com 1480 tweets, conseguimos 399 tweets de teste, ou seja, faltou somente 1. n√£o achamos que 1 tweets afetar√° tanto a base\n",
    "de dados, ent√£o decidimos manter os 1480."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = '13 Reasons Why'\n",
    "\n",
    "n = 1480\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento:\n",
    "t = 600\n",
    "\n",
    "#Filtro de l√≠ngua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 812\n"
     ]
    }
   ],
   "source": [
    "# #Cria um objeto para a captura\n",
    "# api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "# #Inicia a captura, para mais detalhes: ver a documenta√ß√£o do tweepy\n",
    "# i = 1\n",
    "# msgs = []\n",
    "# for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "#     msgs.append(msg.text.lower())\n",
    "#     i += 1\n",
    "#     if i > n:\n",
    "#         break\n",
    "\n",
    "# #Embaralhando as mensagens para reduzir um poss√≠vel vi√©s\n",
    "# list = []\n",
    "# shuffle(msgs)\n",
    "\n",
    "# #Usando o set() para tirar os retweets\n",
    "# listaset = set(msgs)\n",
    "\n",
    "# #Adicionando o resultado do set() a uma lista para evitar o erro TypeError: 'set' object is not subscriptable\n",
    "# for value in listaset:\n",
    "#     list.append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# #Linhas abaixo foram comentadas uma vez que o conjunto de dados era o mesmo, mas o n√∫mero de tweets foi alterado.\n",
    "\n",
    "# # #Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\n",
    "# # if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "#     #Abre o arquivo para escrita\n",
    "# writer = pd.ExcelWriter('{0} novo.xlsx'.format(produto))\n",
    "\n",
    "#     #divide o conjunto de mensagens em duas planilhas\n",
    "# dft = pd.DataFrame({'Treinamento' : pd.Series(list[:t])})\n",
    "# dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "# dfc = pd.DataFrame({'Teste' : pd.Series(list[t:])})\n",
    "# dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "#     #fecha o arquivo\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETAPA 4 - Classifica√ß√£o manual dos tweets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previamente, foram estabelecidas 4 categorias para a classifica√ß√£o das mensagens, entre elas,\n",
    "\n",
    "* \t***P*** - Positivo ‚Äì se a mensagem transmitida for positiva;\n",
    "*\t***N*** - Negativo ‚Äì se a mensagem transmitida for negativa;\n",
    "*\t***O*** - Irrelevante ‚Äì se a mensagem transmitida n√£o for relevante para an√°lise e/ou n√£o se encaixar em nenhuma das outras categorias;\n",
    "*\t***R*** - Rea√ß√£o ‚Äì se a mensagem transmitida for uma rea√ß√£o sobre algum epis√≥dio, temporada, ou da s√©rie em geral.\n",
    "\n",
    "Estabelecidas as categorias e selecionados os tweets, ser√° criada uma base de treinamento, na qual as mensagens ser√£o qualificadas manualmente no excel de acordo com as categoria mais prop√≠cias. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### ETAPA 5 - Montando o Classificador Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "O algoritmo de Naive Bayes √© um classificador probabil√≠stico baseado no teorema de Bayes, utilizado no processo de machine learning. O algoritmo sup√µe que uma caracter√≠stica independe da outra para acontecer, ou seja, mesmo na presen√ßa de uma caracter√≠stica particular em uma classe, isso n√£o afeta na probabilidade de qualquer caracter√≠stica ocorrer. O teorema de bayes √© escrito da seguinte forma:\n",
    "\n",
    "*** colocar a formula de bayes ***\n",
    "\n",
    " Esse algoritmo √© amplamente utilizado na atualidade, por ser simples e pr√°tico. Uma de suas aplica√ß√µes √© na an√°lise de sentimentos, base do projeto e muito √∫til para o setor de marketing ver a rea√ß√£o do p√∫blico a um produto. Um outro exemplo de aplica√ß√£o √© no reconhecimento facial\n",
    " previsao do tempo\n",
    " diagnostico medico\n",
    " reconhecimento de d√≠gitos\n",
    " detecacao de spam\n",
    " cattegorizacao de noticias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse m√©todo ser√° utilizado no projeto, uma vez que permite calcular a probabilidade de uma mensagem ser positiva, por exemplo, dada as palavras utilizadas, assumindo que as palavras em um tweet n√£o tem nenhuma rela√ß√£o entre elas.\n",
    "\n",
    "A partir do nosso modelo, poder√≠amos reescrever o teorema de bayes da seguinte forma:\n",
    "\n",
    "*** colocar a formula de bayes nosso modelo ***\n",
    "\n",
    "A vari√°vel C √© a classe vari√°vel que representa se um tweet ser√° positivo, negativo, irrelevante ou uma rea√ß√£o, a partir das condi√ß√µes estabelecidas (probabilidade de ocorr√™ncia de uma palavra dada as condi√ß√µes). A vari√°vel P representa as palavras ocorridas nos tweets. P pode ser:\n",
    "\n",
    "*** colocar os possiveis valores de P ***\n",
    "\n",
    "Substituindo P por cada uma das poss√≠veis palavras, temos:\n",
    "\n",
    "*** colocar a formula de bayes nosso modelo  com valores de P***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para implementar esse algoritmo, uma nova tabela deve ser criada com as palavras e suas respectivas frequ√™ncias relativas em cada uma das categorias. Por√©m antes disso, dever√° ser feita uma limpeza das mensagens, removendo pontua√ß√µes e caracteres que n√£o conv√©m a an√°lise.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\n",
    "    \"\"\"\n",
    "    punctuation = '[!\\-.:?;‚Ä¢,]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>algu√©m aq ja assistiu a 3¬∞ temp de 13 reasons ...</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(na 3¬∞ temporada de 13 reasons why) eu estou t...</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13 ep de 13 reasons why p tentar fazer vc sent...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nossa nem sabia que tinha lan√ßado a 3¬∞ tempora...</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>estava come√ßando a ver  o primeiro epis√≥dio de...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento Categoria\n",
       "0  algu√©m aq ja assistiu a 3¬∞ temp de 13 reasons ...         O\n",
       "1  (na 3¬∞ temporada de 13 reasons why) eu estou t...         R\n",
       "2  13 ep de 13 reasons why p tentar fazer vc sent...         N\n",
       "3  nossa nem sabia que tinha lan√ßado a 3¬∞ tempora...         O\n",
       "4  estava come√ßando a ver  o primeiro epis√≥dio de...         N"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel = pd.read_excel('13 Reasons Why v2.xlsx', sheet_name='Treinamento')\n",
    "excel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Clas_manual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a coisa mais idiota de 13 reasons why foi colo...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atribu√≠ nota 8 ao epis√≥dio 3x1 - yeah. i'm the...</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt @citou13reasons: ''quando voc√™ julga uma pe...</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>terminei 13 reasons why tamb√©m, meu hobbie √© c...</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @wivisampaio: saiu a nova temporada de elit...</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste Clas_manual\n",
       "0  a coisa mais idiota de 13 reasons why foi colo...           N\n",
       "1  atribu√≠ nota 8 ao epis√≥dio 3x1 - yeah. i'm the...           O\n",
       "2  rt @citou13reasons: ''quando voc√™ julga uma pe...           O\n",
       "3  terminei 13 reasons why tamb√©m, meu hobbie √© c...           R\n",
       "4  rt @wivisampaio: saiu a nova temporada de elit...           O"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel_treino = pd.read_excel('13 Reasons Why v2.xlsx', sheet_name='Teste')\n",
    "excel_treino.rename(columns={'Unnamed: 1':'Clas_manual'}, inplace=True)\n",
    "excel_treino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reasons           72\n",
       "why               68\n",
       "13                68\n",
       "de                62\n",
       "a                 38\n",
       "temporada         29\n",
       "que               20\n",
       "o                 14\n",
       "√©                 13\n",
       "eu                13\n",
       "foi               12\n",
       "e                 11\n",
       "da                10\n",
       "s√©rie             10\n",
       "essa               9\n",
       "uma                9\n",
       "t√°                 9\n",
       "mas                9\n",
       "q                  9\n",
       "muito              8\n",
       "boa                8\n",
       "terceira           8\n",
       "n√£o                8\n",
       "ao                 7\n",
       "foda               7\n",
       "nota               7\n",
       "atribu√≠            7\n",
       "#bancodeseries     7\n",
       "epis√≥dio           7\n",
       "to                 6\n",
       "                  ..\n",
       "√∫nica              1\n",
       "molestia           1\n",
       "agora              1\n",
       "''13               1\n",
       "todo               1\n",
       "pelo               1\n",
       "l√°                 1\n",
       "problems           1\n",
       "gosto              1\n",
       "sobreviv√™ncia      1\n",
       "discutidas         1\n",
       "fenomenal          1\n",
       "ai                 1\n",
       "tempo              1\n",
       "consegue           1\n",
       "deme               1\n",
       "sentir             1\n",
       "estou              1\n",
       "sei                1\n",
       "estava             1\n",
       "d+                 1\n",
       "opini√£o            1\n",
       "co‚Ä¶                1\n",
       "@botts___          1\n",
       "coi‚Ä¶               1\n",
       "jensen             1\n",
       "aff                1\n",
       "pessoas            1\n",
       "3x7                1\n",
       "fazendo            1\n",
       "Length: 423, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fun√ß√£o para limpar e criar tabela de frequ√™ncias relativas\n",
    "\n",
    "def FreqRel(cat):\n",
    "    texto_completo = ' '.join(excel[excel.Categoria==cat].Treinamento)\n",
    "    semhttp = re.sub(r'http\\S+', '', texto_completo)\n",
    "    text_limpo = cleanup(semhttp)\n",
    "    rel = text_limpo.split()\n",
    "    freq_rel = pd.Series(rel).value_counts(True)\n",
    "    return freq_rel\n",
    "\n",
    "def FreqAbs(cat):\n",
    "    texto_completo = ' '.join(excel[excel.Categoria==cat].Treinamento)\n",
    "    semhttp = re.sub(r'http\\S+', '', texto_completo)\n",
    "    text_limpo = cleanup(semhttp)\n",
    "    rel = text_limpo.split()\n",
    "    freq_abs = pd.Series(rel).value_counts()\n",
    "    return freq_abs\n",
    "\n",
    "FreqAbs('P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estas fun√ß√µes dividem a fun√ß√£o anterior\n",
    "def Limpa(texto):\n",
    "    semhttp = re.sub(r'http\\S+', '', texto)\n",
    "    text_limpo = cleanup(semhttp)\n",
    "    rel = text_limpo.split()\n",
    "    return(rel)\n",
    "\n",
    "# def FreqRel(Limpa):\n",
    "#     print(Limpa(texto_completo))\n",
    "#     freq_rel = pd.Series(Limpa).value_counts(True)\n",
    "#     return freq_rel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Descobrindo P(N), P(R), P(P) e P(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui ser√£o estabelecidas as probabilididades de ocorr√™ncia de cada categoria, a partir da tabela da frequ√™ncia relativa das palavras da base de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas as palavras somadas:\n",
      "10095\n"
     ]
    }
   ],
   "source": [
    "texto_1 = ' '.join(excel[excel.Categoria=='O'].Treinamento)\n",
    "texto_2 = ' '.join(excel[excel.Categoria=='R'].Treinamento)\n",
    "texto_3 = ' '.join(excel[excel.Categoria=='P'].Treinamento)\n",
    "texto_4 = ' '.join(excel[excel.Categoria=='N'].Treinamento)\n",
    "\n",
    "texto_1 = Limpa(texto_1)\n",
    "texto_2 = Limpa(texto_2)\n",
    "texto_3 = Limpa(texto_3)\n",
    "texto_4 = Limpa(texto_4)\n",
    "\n",
    "#juntando todos os textos\n",
    "texto_enorme = texto_1 + texto_2 + texto_3 + texto_4\n",
    "set(texto_enorme)\n",
    "dic_global = 0\n",
    "for palavra in texto_enorme:\n",
    "        dic_global+=1\n",
    "    \n",
    "print('Todas as palavras somadas:')\n",
    "print(dic_global)\n",
    "\n",
    "def prob_cat(cat):\n",
    "    palavras = 0\n",
    "    texto_completo = ' '.join(excel[excel.Categoria==cat].Treinamento)\n",
    "    texto_completo.replace('‚Ä¢', '')\n",
    "    semhttp = re.sub(r'http\\S+', '', texto_completo)\n",
    "    text_limpo = cleanup(semhttp)\n",
    "    rel = text_limpo.split()\n",
    "    set(rel)\n",
    "    # Para verificar se o c√≥digo era coerente, imprimimos o total de palavras de cada categoria\n",
    "    for palavra in rel:\n",
    "        palavras += 1\n",
    "    prob_final = palavras/dic_global\n",
    "    return prob_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidade da Categoria 'Neutro'\n",
      "0.5090638930163447\n",
      "\n",
      "Probabilidade da Categoria 'Negativo'\n",
      "0.2220901436354631\n",
      "\n",
      "Probabilidade da Categoria 'Positivo'\n",
      "0.11362060425953442\n",
      "\n",
      "Probabilidade da Categoria 'Rea√ß√£o'\n",
      "0.15522535908865776\n",
      "\n",
      "Probabilidade Total (se tudo der certo, deve ser 1)\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Probabilidade da Categoria 'Neutro'\")\n",
    "print(prob_cat('O'))\n",
    "print('')\n",
    "print(\"Probabilidade da Categoria 'Negativo'\")\n",
    "print(prob_cat('N'))\n",
    "print('')\n",
    "print(\"Probabilidade da Categoria 'Positivo'\")\n",
    "print(prob_cat('P'))\n",
    "print('')\n",
    "print(\"Probabilidade da Categoria 'Rea√ß√£o'\")\n",
    "print(prob_cat('R'))\n",
    "\n",
    "\n",
    "\n",
    "print('')\n",
    "print(\"Probabilidade Total (se tudo der certo, deve ser 1)\")\n",
    "print(prob_cat('O') + prob_cat('N') + prob_cat('P') + prob_cat('R'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reasons          268\n",
       "13               264\n",
       "why              255\n",
       "de               243\n",
       "a                154\n",
       "e                131\n",
       "temporada         95\n",
       "elite             78\n",
       "que               70\n",
       "eu                61\n",
       "o                 51\n",
       "n√£o               50\n",
       "assistir          49\n",
       "rt                42\n",
       "sobre             34\n",
       "3                 34\n",
       "pra               34\n",
       "2                 32\n",
       "√©                 31\n",
       "da                30\n",
       "do                30\n",
       "1                 29\n",
       "ver               29\n",
       "terceira          28\n",
       "s√©ries            27\n",
       "vou               27\n",
       "q                 26\n",
       "to                24\n",
       "com               23\n",
       "se                23\n",
       "                ... \n",
       "bizarros           1\n",
       "importante         1\n",
       "lembrou            1\n",
       "esses              1\n",
       "adole              1\n",
       "finalizadas        1\n",
       "souberam           1\n",
       "rapid√£o            1\n",
       "tyler              1\n",
       "aq                 1\n",
       "ccxp               1\n",
       "viram              1\n",
       "@jvjbts7           1\n",
       "enfim              1\n",
       "feira              1\n",
       "percebeu           1\n",
       "imperfeito         1\n",
       "tomar              1\n",
       "seg‚Ä¶               1\n",
       "üôÑüôÑ                 1\n",
       "jeito              1\n",
       "feios              1\n",
       "@seriesbrasil      1\n",
       "nossa              1\n",
       "outros             1\n",
       "@nathlaino         1\n",
       "maravilhosas       1\n",
       "mano               1\n",
       "comparei           1\n",
       "apanhas            1\n",
       "Length: 1288, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    Fqr = FreqAbs('R')\n",
    "    Fqn = FreqAbs('N')\n",
    "    Fqp = FreqAbs('P')\n",
    "    Fqo = FreqAbs('O')\n",
    "except: \n",
    "    pass\n",
    "\n",
    "FreqAbs('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Neutro_set = set(FreqRel(0).index)\n",
    "Reacao_set = set(FreqRel('R').index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   P(N | palavras) = P(N) * P(cada_palavra | N)\n",
    "\n",
    "N√ÉO √â PRECISO DIVIDIR PELA PROBABILIDADE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pR = np.sum(Fqr)\n",
    "pN = np.sum(Fqn)\n",
    "pP = np.sum(Fqp)\n",
    "pO = np.sum(Fqo)\n",
    "\n",
    "alpha = 1\n",
    "V = 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1567"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isso t√° certo, talkey?\n",
    "\n",
    "prob_R = 1\n",
    "prob_tweet = 1\n",
    "dicR = {}\n",
    "for tweet in excel_treino['Teste']:\n",
    "    tweet = cleanup(tweet)\n",
    "    pal_tweet = tweet.split()\n",
    "    probabilidade = 1\n",
    "    for palavra_teste in pal_tweet:\n",
    "        # Calcula prob da palavra com smoothing.\n",
    "        c = 0\n",
    "        if palavra_teste in Fqr:\n",
    "            c = Fqr[palavra_teste]\n",
    "        p = (c + alpha)/(pR + alpha*V)\n",
    "        prob_tweet = prob_tweet * freq\n",
    "    prob_tweet = prob_tweet * prob_cat('R')\n",
    "    dicR[tweet] = prob_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_N = 1\n",
    "prob_tweet = 1\n",
    "dicN = {}\n",
    "for tweet in excel_treino['Teste']:\n",
    "    tweet = cleanup(tweet)\n",
    "    pal_tweet = tweet.split()\n",
    "    probabilidade = 1\n",
    "    for palavra_teste in pal_tweet:\n",
    "        #PERGUNTAR!!\n",
    "        c = 0\n",
    "        if palavra_teste in Fqn:\n",
    "            c = Fqn[palavra_teste]\n",
    "        p = (c + alpha)/(pN + alpha*V)\n",
    "        prob_tweet = prob_tweet * freq\n",
    "    prob_tweet = prob_tweet * prob_cat('N')\n",
    "    dicN[tweet] = prob_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-e4fbb8cc5248>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprob_tweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob_tweet\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprob_tweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob_tweet\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mprob_cat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'P'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mdicP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_tweet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "prob_P = 1\n",
    "prob_tweet = 1\n",
    "dicP = {}\n",
    "for tweet in excel_treino['Teste']:\n",
    "    tweet = cleanup(tweet)\n",
    "    pal_tweet = tweet.split()\n",
    "    for palavra_teste in pal_tweet:\n",
    "        c = 0\n",
    "        if palavra_teste in Fqp:\n",
    "            c = Fqp[palavra_teste]\n",
    "        p = (c + alpha)/(pP + alpha*V)\n",
    "        prob_tweet = prob_tweet * freq\n",
    "    prob_tweet = prob_tweet * prob_cat('P')\n",
    "    dicP[tweet] = math.log(prob_tweet,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_O = 1\n",
    "prob_tweet = 1\n",
    "dicO = {}\n",
    "for tweet in excel_treino['Teste']:\n",
    "    tweet = cleanup(tweet)\n",
    "    pal_tweet = tweet.split()\n",
    "    for palavra_teste in pal_tweet:\n",
    "        c = 0\n",
    "        if palavra_teste in Fqo:\n",
    "            c = Fqo[palavra_teste]\n",
    "        p = (c + alpha)/(pO + alpha*V)\n",
    "        prob_tweet = prob_tweet * freq\n",
    "    prob_tweet = prob_tweet * prob_cat('O')\n",
    "    dicO[tweet] = math.log(prob_tweet,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2220901436354631\n"
     ]
    }
   ],
   "source": [
    "print(dicN['a coisa mais idiota de 13 reasons why foi colocar o zac e a cheryl nas fitas  botaram eles num n√≠vel de fdp igual aos outros desnecess√°rio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dicO['a coisa mais idiota de 13 reasons why foi colocar o zac e a cheryl nas fitas  botaram eles num n√≠vel de fdp igual aos outros desnecess√°rio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dicR['a coisa mais idiota de 13 reasons why foi colocar o zac e a cheryl nas fitas  botaram eles num n√≠vel de fdp igual aos outros desnecess√°rio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dicP['a coisa mais idiota de 13 reasons why foi colocar o zac e a cheryl nas fitas  botaram eles num n√≠vel de fdp igual aos outros desnecess√°rio'])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'que raiva daquele recado que tem no in√≠cio de 13 reasons why \"se voc√™ estiver passando por algo parecido n√£o assist‚Ä¶ https //t co/qemeudou7h'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-f5b1176339ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpal_tweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmaior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdicN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mmaior\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mdicP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mmaior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdicP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtweets_classificados\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'P'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'que raiva daquele recado que tem no in√≠cio de 13 reasons why \"se voc√™ estiver passando por algo parecido n√£o assist‚Ä¶ https //t co/qemeudou7h'"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> parent of 170ba4e... Update Projeto2_layout.ipynb
   "source": [
    "tweets_classificados = []\n",
    "\n",
    "for tweet in excel_treino['Teste']:\n",
    "    tweet = cleanup(tweet)\n",
    "    pal_tweet = tweet.split()\n",
    "    maior = dicN[tweet]\n",
    "    if maior < dicP[tweet]:\n",
    "        maior = dicP\n",
    "        tweets_classificados.append('P')\n",
    "    elif maior < dicO[tweet]:\n",
    "        maior = dicO\n",
    "        tweets_classificados.append('O') \n",
    "    elif maior < dicR[tweet]:\n",
    "        maior = dicR\n",
    "        tweets_classificados.append('R')\n",
    "    else:\n",
    "        tweets_classificados.append('N')\n",
    "\n",
    "excel_treino['previsto'] = tweets_classificados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acur√°cia:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 83,
=======
   "execution_count": null,
>>>>>>> parent of 170ba4e... Update Projeto2_layout.ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 0\n",
    "falso_P = 0\n",
    "O = 0\n",
    "falso_O = 0\n",
    "R = 0\n",
    "falso_R = 0\n",
    "N = 0\n",
    "falso_N = 0\n",
    "\n",
    "\n",
    "total = len(excel_treino[\"Teste\"])\n",
    "\n",
    "for [e,i] in zip(excel_treino[\"Teste\"], excel_treino[\"previsto\"]):\n",
    "    if e == 1:\n",
    "        if i == 1:\n",
    "            P += 1\n",
    "        else: \n",
    "            falso_P += 1\n",
    "    if e == 2:            \n",
    "        if i == 2:\n",
    "            N +=1\n",
    "        else:\n",
    "            falso_N +=1\n",
    "    if e == 2:            \n",
    "        if i == 2:\n",
    "            O +=1\n",
    "        else:\n",
    "            falso_O +=1\n",
    "    if e == 2:            \n",
    "        if i == 2:\n",
    "            R +=1\n",
    "        else:\n",
    "            falso_R +=1"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 84,
=======
   "execution_count": null,
>>>>>>> parent of 170ba4e... Update Projeto2_layout.ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Positivos Verdadeiros: \", round((P/total)*100,2), \"%\")\n",
    "print(\"Positivos Falsos: \", round((falso_P/total)*100, 2), \"%\")\n",
    "print(\"Negativos Verdadeiros: \", round((N/total)*100,2), \"%\")\n",
    "print(\"Negativos Falsos: \", round((falso_N/total)*100, 2), \"%\")\n",
    "print(\"Neutros Verdadeiros: \", round((O/total)*100,2), \"%\")\n",
    "print(\"Neutros Falsos: \", round((falso_O/total)*100, 2), \"%\")\n",
    "print(\"Rea√ß√µes Verdadeiros: \", round((R/total)*100,2), \"%\")\n",
    "print(\"Rea√ß√µes Falsos: \", round((falso_R/total)*100, 2), \"%\")\n",
    "print(\"_\"*35)\n",
    "\n",
    "print(\"Acertos: \", round(((P/total)+(N/total)+(O/total)+(R/total))*100,2), \"%\")\n",
    "print(\"Erros: \", round(((falso_P/total)+(falso_N/total)+(falso_R/total)+(falso_O/total))*100,2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DASHBOARD**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 85,
=======
   "execution_count": null,
>>>>>>> parent of 170ba4e... Update Projeto2_layout.ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(tweets_classificados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from time import sleep\n",
    "# import pandas as pd\n",
    "\n",
    "# for e in range(3):\n",
    "#     !jupyter nbconvert --to notebook --execute Projeto2_layout.ipynb\n",
    "#     dashboard = pd.readExcel(\"13 Reasons Why novo.xlsx\")\n",
    "#     print(f\"dashoard: {dashoard}\")\n",
    "#     sleep(5)\n",
    "\n",
    "\n",
    "# excel_treino.to_excel('fill_auto1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'auth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-573da29bb934>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#getting new tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#Cria um objeto para a captura\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_on_rate_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_on_rate_limit_notify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#Inicia a captura, para mais detalhes: ver a documenta√ß√£o do tweepy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'auth' is not defined"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "while True:\n",
    "    #getting new tweets\n",
    "    #Cria um objeto para a captura\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "    #Inicia a captura, para mais detalhes: ver a documenta√ß√£o do tweepy\n",
    "    i = 1\n",
    "    msgs = []\n",
    "    for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "        msgs.append(msg.text.lower())\n",
    "        i += 1\n",
    "        if i > n:\n",
    "            break\n",
    "\n",
    "    #Embaralhando as mensagens para reduzir um poss√≠vel vi√©s\n",
    "    lista = []\n",
    "    shuffle(msgs)\n",
    "\n",
    "    #Usando o set() para tirar os retweets\n",
    "    listaset = set(msgs)\n",
    "\n",
    "    #Adicionando o resultado do set() a uma lista para evitar o erro TypeError: 'set' object is not subscriptable\n",
    "    for value in listaset:\n",
    "        lista.append(value)\n",
    "    \n",
    "    #criando dataframe com novos tweets\n",
    "    df_teste = pd.DataFrame({'Teste' : pd.Series(lista)})\n",
    "    \n",
    "    #classifie new tweets\n",
    "    tweets_classificados = []\n",
    "\n",
    "    for tweet in excel_treino['Teste']:\n",
    "        tweet = cleanup(tweet)\n",
    "        pal_tweet = tweet.split()\n",
    "        maior = dicN[tweet]\n",
    "        if maior < dicP[tweet]:\n",
    "            maior = dicP\n",
    "            tweets_classificados.append('P')\n",
    "        elif maior < dicO[tweet]:\n",
    "            maior = dicO\n",
    "            tweets_classificados.append('O') \n",
    "        elif maior < dicR[tweet]:\n",
    "            maior = dicR\n",
    "            tweets_classificados.append('R')\n",
    "        else:\n",
    "            tweets_classificados.append('N')\n",
    "            \n",
    "    df_teste['Categorias'] = tweets_classificados\n",
    "    \n",
    "    #mostrar na dashboard:\n",
    "    \n",
    "\n",
    "    sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Por que n√£o se pode utilizar o pr√≥prio classificador para gerar mais amostras de treinamento?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Ao se utilizar o pr√≥prio classificador para gerar mais amostras de treinamento, o classificador acaba ficando \n",
    "    'viciado', ou seja, acaba-se por prejudicar os resultados obtidos, e eles acabam n√£o tendo uma qualidade boa.\n",
    "    Seria o contr√°rio de puxar mais tweets, que melhora a qualidade dos dados e dos resultados, por ter um espa√ßo \n",
    "    amostral muito maior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outras limpezas e tranforma√ß√µes:\n",
    "___\n",
    "    - Trocar v√≠rgu√ßas por espa√ßos\n",
    "    - Remover URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outros cen√°rios de Naive Bayes fora do contexto do projeto\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Previs√£o de Chuva\n",
    "    - Filtros de e-mail (Spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**\n",
    "\n",
    "https://towardsdatascience.com/naive-bayes-classifier-81d512f50a7c\n",
    "\n",
    "https://www.geeksforgeeks.org/naive-bayes-classifiers/\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probP = 0\n",
    "# probN = 0\n",
    "# probR = 0\n",
    "# probO = 0\n",
    "# i = 0\n",
    "# dic_catR = {}\n",
    "# dic_catP = {}\n",
    "# dic_catN = {}\n",
    "# dic_catO = {}\n",
    "\n",
    "\n",
    "# #Para cada tweet na planilha:\n",
    "# for tweet in excel_treino['Teste']:\n",
    "#     tweet = cleanup(tweet.lower())\n",
    "#     pal_tweet = tweet.split()\n",
    "#     #Para cada palavra de cada tweet:\n",
    "#     for palavra in pal_tweet:\n",
    "#         um = True\n",
    "#         for palavra1, frequencia in Fqr.items():\n",
    "#             if um == True:\n",
    "#                 #Seta a frquencia inicial de cada palavra para 1\n",
    "#                 dic_catR[tweet] = 1\n",
    "#             um = False\n",
    "#             # probabilidade total s√£o todas as probabilidades das palavras multiplicadas pela probabilidade de certa categoria\n",
    "#             dic_catR[tweet] = dic_catR[tweet] *  prob_cat('R') * frequencia\n",
    "                              \n",
    "#         for palavra1, frequencia in Fqn.items():\n",
    "#             if um == True:\n",
    "#                 dic_catN[tweet] = 1\n",
    "#             um = False\n",
    "#             dic_catN[tweet] = dic_catN[tweet] *  prob_cat('N') * frequencia\n",
    "            \n",
    "#         for palavra1, frequencia in Fqp.items():\n",
    "#             if um == True:\n",
    "#                 dic_catP[tweet] = 1\n",
    "#             um = False\n",
    "#             dic_catP[tweet] = dic_catP[tweet] *  prob_cat('P') * frequencia\n",
    "\n",
    "#         for palavra1, frequencia in Fqo.items():\n",
    "#             if um == True:\n",
    "#                 dic_catP[tweet] = 1\n",
    "#             um = False\n",
    "#             dic_catO[tweet] = dic_catP[tweet] *  prob_cat('O') * frequencia     \n",
    "\n",
    "#         #N√£o precisa dividir pela probabilidade do tweet pois cancelaria.\n",
    "    \n",
    "# # fazer contador pra ver qual √© a maior probabilidade, e adicionar em uma nova coluna do dataframe\n",
    "# #  DataFrame.insert(2, 'Predi√ß√£o', [lista com letra de cada linha], True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
