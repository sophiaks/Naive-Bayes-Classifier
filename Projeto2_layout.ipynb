{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Projeto 2 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Amanda Rosa do Carmo\n",
    "\n",
    "Nome: Beatriz Cabral\n",
    "\n",
    "Nome: Sophia Kerber Shigueoka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introdu√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo desse projeto √© criar um classificador capaz de analisar como a audi√™ncia de ‚Äú13 reasons why‚Äù, uma s√©rie de televis√£o pol√™mica, est√° reagindo. Para tal fim, ser√° feita uma an√°lise da probabilidade de um tweet ser relevante dada as palavras do seu conte√∫do, utilizando o princ√≠pio do algoritimo de Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Desenvolvimento e metodologia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   A fim de simplificar a explica√ß√£o do processo de desenvolvimento do projeto, ele ser√° dividido em  X etapas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETAPA 1 - Preparando o ambiente no jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa etapa, ser√£o baixadas e importadas todas as bibliotecas relevantes para o c√≥digo, bem como implementadas todas as fun√ß√µes a serem utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Importando as bibliotecas\n",
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\n",
    "    \"\"\"\n",
    "    punctuation = '[!\\-.:?;‚Ä¢,]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### ETAPA 2 - Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***@KerberSophie***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui ser√° feita a autentica√ß√£o no twitter, a partir de um c√≥digo obtido no pr√≥prio site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autentica√ß√£o do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @KerberSophie\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. N√£o modificar\n",
    "# auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "# auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETAPA 3 - Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, iremos fazer a coleta dos dados, nesse caso de tweets, a partir da keyword ‚Äú13 reasons why‚Äù escolhida. Feita a coleta, os dados foram salvos dentro de uma planilha no excel. Para importar as mensagens do Twitter, foi necess√°rio o uso da biblioteca Tweepy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantidade m√≠nima de mensagens capturadas:\n",
    "Escolhemos 1480 a partir de um m√©todo emp√≠rico. Quando testamos com 1000 n√£o conseguimos tweets suficientes, e chegamos\n",
    "a conclus√£o de que o problema era proveniente do set(), que diminu√≠a a quantidade de tweets baixados. Assim, decidiu-se\n",
    "aumentar a quantidade de tweets para 1500, j√° que com 1000 ficaram falatando 360 tweets. Com 1500, ficamos com 20 tweets a mais.\n",
    "como eram somente 20 tweets, imaginamos que poucos deles seriam retweets, ent√£o tiramos exatamente 20 tweets dos 1500.\n",
    "Com 1480 tweets, conseguimos 399 tweets de teste, ou seja, faltou somente 1. n√£o achamos que 1 tweets afetar√° tanto a base\n",
    "de dados, ent√£o decidimos manter os 1480."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = '13 Reasons Why'\n",
    "\n",
    "n = 1480\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento:\n",
    "t = 600\n",
    "\n",
    "#Filtro de l√≠ngua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 812\n"
     ]
    }
   ],
   "source": [
    "# #Cria um objeto para a captura\n",
    "# api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "# #Inicia a captura, para mais detalhes: ver a documenta√ß√£o do tweepy\n",
    "# i = 1\n",
    "# msgs = []\n",
    "# for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "#     msgs.append(msg.text.lower())\n",
    "#     i += 1\n",
    "#     if i > n:\n",
    "#         break\n",
    "\n",
    "# #Embaralhando as mensagens para reduzir um poss√≠vel vi√©s\n",
    "# list = []\n",
    "# shuffle(msgs)\n",
    "\n",
    "# #Usando o set() para tirar os retweets\n",
    "# listaset = set(msgs)\n",
    "\n",
    "# #Adicionando o resultado do set() a uma lista para evitar o erro TypeError: 'set' object is not subscriptable\n",
    "# for value in listaset:\n",
    "#     list.append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# #Linhas abaixo foram comentadas uma vez que o conjunto de dados era o mesmo, mas o n√∫mero de tweets foi alterado.\n",
    "\n",
    "# # #Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\n",
    "# # if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "#     #Abre o arquivo para escrita\n",
    "# writer = pd.ExcelWriter('{0} novo.xlsx'.format(produto))\n",
    "\n",
    "#     #divide o conjunto de mensagens em duas planilhas\n",
    "# dft = pd.DataFrame({'Treinamento' : pd.Series(list[:t])})\n",
    "# dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "# dfc = pd.DataFrame({'Teste' : pd.Series(list[t:])})\n",
    "# dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "#     #fecha o arquivo\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETAPA 4 - Classifica√ß√£o manual dos tweets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previamente, foram estabelecidas 4 categorias para a classifica√ß√£o das mensagens, entre elas,\n",
    "\n",
    "* \t***P*** - Positivo ‚Äì se a mensagem transmitida for positiva;\n",
    "*\t***N*** - Negativo ‚Äì se a mensagem transmitida for negativa;\n",
    "*\t***O*** - Irrelevante ‚Äì se a mensagem transmitida n√£o for relevante para an√°lise e/ou n√£o se encaixar em nenhuma das outras categorias;\n",
    "*\t***R*** - Rea√ß√£o ‚Äì se a mensagem transmitida for uma rea√ß√£o sobre algum epis√≥dio, temporada, ou da s√©rie em geral.\n",
    "\n",
    "Estabelecidas as categorias e selecionados os tweets, ser√° criada uma base de treinamento, na qual as mensagens ser√£o qualificadas manualmente no excel de acordo com as categoria mais prop√≠cias. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### ETAPA 5 - Montando o Classificador Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "O algoritmo de Naive Bayes √© um classificador probabil√≠stico baseado no teorema de Bayes, utilizado no processo de machine learning. O algoritmo sup√µe que uma caracter√≠stica independe da outra para acontecer, ou seja, mesmo na presen√ßa de uma caracter√≠stica particular em uma classe, isso n√£o afeta na probabilidade de qualquer caracter√≠stica ocorrer. O teorema de bayes √© escrito da seguinte forma:\n",
    "\n",
    "*** colocar a formula de bayes ***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse m√©todo ser√° utilizado no projeto, uma vez que permite calcular a probabilidade de uma mensagem ser positiva, por exemplo, dada as palavras utilizadas, assumindo que as palavras em um tweet n√£o tem nenhuma rela√ß√£o entre elas.\n",
    "\n",
    "A partir do nosso modelo, poder√≠amos reescrever o teorema de bayes da seguinte forma:\n",
    "\n",
    "*** colocar a formula de bayes nosso modelo ***\n",
    "\n",
    "A vari√°vel C √© a classe vari√°vel que representa se um tweet ser√° positivo, negativo, irrelevante ou uma rea√ß√£o, a partir das condi√ß√µes estabelecidas (probabilidade de ocorr√™ncia de uma palavra dada as condi√ß√µes). A vari√°vel P representa as palavras ocorridas nos tweets. P pode ser:\n",
    "\n",
    "*** colocar os possiveis valores de P ***\n",
    "\n",
    "Substituindo P por cada uma das poss√≠veis palavras, temos:\n",
    "\n",
    "*** colocar a formula de bayes nosso modelo  com valores de P***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para implementar esse algoritmo, uma nova tabela deve ser criada com as palavras e suas respectivas frequ√™ncias relativas em cada uma das categorias. Por√©m antes disso, dever√° ser feita uma limpeza das mensagens, removendo pontua√ß√µes e caracteres que n√£o conv√©m a an√°lise.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\n",
    "    \"\"\"\n",
    "    punctuation = '[!\\-.:?;‚Ä¢,]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>algu√©m aq ja assistiu a 3¬∞ temp de 13 reasons ...</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(na 3¬∞ temporada de 13 reasons why) eu estou t...</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13 ep de 13 reasons why p tentar fazer vc sent...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nossa nem sabia que tinha lan√ßado a 3¬∞ tempora...</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>estava come√ßando a ver  o primeiro epis√≥dio de...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento Categoria\n",
       "0  algu√©m aq ja assistiu a 3¬∞ temp de 13 reasons ...         O\n",
       "1  (na 3¬∞ temporada de 13 reasons why) eu estou t...         R\n",
       "2  13 ep de 13 reasons why p tentar fazer vc sent...         N\n",
       "3  nossa nem sabia que tinha lan√ßado a 3¬∞ tempora...         O\n",
       "4  estava come√ßando a ver  o primeiro epis√≥dio de...         N"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel = pd.read_excel('13 Reasons Why v2.xlsx', sheet_name='Treinamento')\n",
    "excel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Clas_manual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a coisa mais idiota de 13 reasons why foi colo...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atribu√≠ nota 8 ao epis√≥dio 3x1 - yeah. i'm the...</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt @citou13reasons: ''quando voc√™ julga uma pe...</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>terminei 13 reasons why tamb√©m, meu hobbie √© c...</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @wivisampaio: saiu a nova temporada de elit...</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste Clas_manual\n",
       "0  a coisa mais idiota de 13 reasons why foi colo...           N\n",
       "1  atribu√≠ nota 8 ao epis√≥dio 3x1 - yeah. i'm the...           O\n",
       "2  rt @citou13reasons: ''quando voc√™ julga uma pe...           O\n",
       "3  terminei 13 reasons why tamb√©m, meu hobbie √© c...           R\n",
       "4  rt @wivisampaio: saiu a nova temporada de elit...           O"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel_treino = pd.read_excel('13 Reasons Why v2.xlsx', sheet_name='Teste')\n",
    "excel_treino.rename(columns={'Unnamed: 1':'Clas_manual'}, inplace=True)\n",
    "excel_treino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reasons           0.062772\n",
       "13                0.059285\n",
       "why               0.059285\n",
       "de                0.054054\n",
       "a                 0.033130\n",
       "temporada         0.025283\n",
       "que               0.017437\n",
       "o                 0.012206\n",
       "eu                0.011334\n",
       "√©                 0.011334\n",
       "foi               0.010462\n",
       "e                 0.009590\n",
       "s√©rie             0.008718\n",
       "da                0.008718\n",
       "essa              0.007847\n",
       "uma               0.007847\n",
       "q                 0.007847\n",
       "t√°                0.007847\n",
       "mas               0.007847\n",
       "boa               0.006975\n",
       "n√£o               0.006975\n",
       "muito             0.006975\n",
       "terceira          0.006975\n",
       "#bancodeseries    0.006103\n",
       "ao                0.006103\n",
       "atribu√≠           0.006103\n",
       "epis√≥dio          0.006103\n",
       "nota              0.006103\n",
       "foda              0.006103\n",
       "rt                0.005231\n",
       "                    ...   \n",
       "namoral           0.000872\n",
       "riverdale         0.000872\n",
       "pais              0.000872\n",
       "@guimenekkkj      0.000872\n",
       "√≥tima             0.000872\n",
       "fico              0.000872\n",
       "critiquei         0.000872\n",
       "world             0.000872\n",
       "'13               0.000872\n",
       "3¬∫                0.000872\n",
       "finalmente        0.000872\n",
       "entende           0.000872\n",
       "ai                0.000872\n",
       "are               0.000872\n",
       "chorar            0.000872\n",
       "genial            0.000872\n",
       "bem               0.000872\n",
       "fudeu             0.000872\n",
       "enrolada          0.000872\n",
       "devia             0.000872\n",
       "ate               0.000872\n",
       "gostosa           0.000872\n",
       "li                0.000872\n",
       "julguei           0.000872\n",
       "can               0.000872\n",
       "@mmazzoco1        0.000872\n",
       "you               0.000872\n",
       "primeiro          0.000872\n",
       "gostou            0.000872\n",
       "deus              0.000872\n",
       "Length: 423, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fun√ß√£o para limpar e criar tabela de frequ√™ncias relativas\n",
    "\n",
    "def FreqRel(cat):\n",
    "    texto_completo = ' '.join(excel[excel.Categoria==cat].Treinamento)\n",
    "    semhttp = re.sub(r'http\\S+', '', texto_completo)\n",
    "    text_limpo = cleanup(semhttp)\n",
    "    rel = text_limpo.split()\n",
    "    freq_rel = pd.Series(rel).value_counts(True)\n",
    "    return freq_rel\n",
    "\n",
    "FreqRel('P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estas fun√ß√µes dividem a fun√ß√£o anterior\n",
    "def Limpa(texto):\n",
    "    semhttp = re.sub(r'http\\S+', '', texto)\n",
    "    text_limpo = cleanup(semhttp)\n",
    "    rel = text_limpo.split()\n",
    "    return(rel)\n",
    "\n",
    "# def FreqRel(Limpa):\n",
    "#     print(Limpa(texto_completo))\n",
    "#     freq_rel = pd.Series(Limpa).value_counts(True)\n",
    "#     return freq_rel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Descobrindo P(N), P(R), P(P) e P(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas as palavras somadas:\n",
      "10095\n"
     ]
    }
   ],
   "source": [
    "texto_1 = ' '.join(excel[excel.Categoria=='O'].Treinamento)\n",
    "texto_2 = ' '.join(excel[excel.Categoria=='R'].Treinamento)\n",
    "texto_3 = ' '.join(excel[excel.Categoria=='P'].Treinamento)\n",
    "texto_4 = ' '.join(excel[excel.Categoria=='N'].Treinamento)\n",
    "\n",
    "texto_1 = Limpa(texto_1)\n",
    "texto_2 = Limpa(texto_2)\n",
    "texto_3 = Limpa(texto_3)\n",
    "texto_4 = Limpa(texto_4)\n",
    "\n",
    "#juntando todos os textos\n",
    "texto_enorme = texto_1 + texto_2 + texto_3 + texto_4\n",
    "set(texto_enorme)\n",
    "dic_global = 0\n",
    "for palavra in texto_enorme:\n",
    "        dic_global+=1\n",
    "    \n",
    "print('Todas as palavras somadas:')\n",
    "print(dic_global)\n",
    "\n",
    "def prob_cat(cat):\n",
    "    palavras = 0\n",
    "    texto_completo = ' '.join(excel[excel.Categoria==cat].Treinamento)\n",
    "    texto_completo.replace('‚Ä¢', '')\n",
    "    semhttp = re.sub(r'http\\S+', '', texto_completo)\n",
    "    text_limpo = cleanup(semhttp)\n",
    "    rel = text_limpo.split()\n",
    "    set(rel)\n",
    "    # Para verificar se o c√≥digo era coerente, imprimimos o total de palavras de cada categoria\n",
    "    for palavra in rel:\n",
    "        palavras += 1\n",
    "    prob_final = palavras/dic_global\n",
    "    return prob_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidade da Categoria 'Neutro'\n",
      "0.5090638930163447\n",
      "\n",
      "Probabilidade da Categoria 'Negativo'\n",
      "0.2220901436354631\n",
      "\n",
      "Probabilidade da Categoria 'Positivo'\n",
      "0.11362060425953442\n",
      "\n",
      "Probabilidade da Categoria 'Rea√ß√£o'\n",
      "0.15522535908865776\n",
      "\n",
      "Probabilidade Total (se tudo der certo, deve ser 1)\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Probabilidade da Categoria 'Neutro'\")\n",
    "print(prob_cat('O'))\n",
    "print('')\n",
    "print(\"Probabilidade da Categoria 'Negativo'\")\n",
    "print(prob_cat('N'))\n",
    "print('')\n",
    "print(\"Probabilidade da Categoria 'Positivo'\")\n",
    "print(prob_cat('P'))\n",
    "print('')\n",
    "print(\"Probabilidade da Categoria 'Rea√ß√£o'\")\n",
    "print(prob_cat('R'))\n",
    "\n",
    "\n",
    "\n",
    "print('')\n",
    "print(\"Probabilidade Total (se tudo der certo, deve ser 1)\")\n",
    "print(prob_cat('O') + prob_cat('N') + prob_cat('P') + prob_cat('R'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reasons             0.052150\n",
       "13                  0.051372\n",
       "why                 0.049621\n",
       "de                  0.047285\n",
       "a                   0.029967\n",
       "e                   0.025491\n",
       "temporada           0.018486\n",
       "elite               0.015178\n",
       "que                 0.013621\n",
       "eu                  0.011870\n",
       "o                   0.009924\n",
       "n√£o                 0.009730\n",
       "assistir            0.009535\n",
       "rt                  0.008173\n",
       "pra                 0.006616\n",
       "3                   0.006616\n",
       "sobre               0.006616\n",
       "2                   0.006227\n",
       "√©                   0.006032\n",
       "da                  0.005838\n",
       "do                  0.005838\n",
       "1                   0.005643\n",
       "ver                 0.005643\n",
       "terceira            0.005449\n",
       "vou                 0.005254\n",
       "s√©ries              0.005254\n",
       "q                   0.005059\n",
       "to                  0.004670\n",
       "com                 0.004476\n",
       "se                  0.004476\n",
       "                      ...   \n",
       "show                0.000195\n",
       "marina              0.000195\n",
       "revoltado           0.000195\n",
       "chiba               0.000195\n",
       "wtf                 0.000195\n",
       "@lucasbelis         0.000195\n",
       "c                   0.000195\n",
       "qualquer            0.000195\n",
       "inesperadas         0.000195\n",
       "foto                0.000195\n",
       "@rebeldevermelho    0.000195\n",
       "@alencaarx_         0.000195\n",
       "education           0.000195\n",
       "assassinato         0.000195\n",
       "tempora‚Ä¶            0.000195\n",
       "confirmar           0.000195\n",
       "precisa             0.000195\n",
       "aben√ßoe             0.000195\n",
       "totalmente          0.000195\n",
       "gat                 0.000195\n",
       "comigo              0.000195\n",
       "2t                  0.000195\n",
       "cabelo              0.000195\n",
       "jeito               0.000195\n",
       "70's                0.000195\n",
       "aiiiiü•µüòª             0.000195\n",
       "espero              0.000195\n",
       "qtas                0.000195\n",
       "talvez              0.000195\n",
       "pe‚Ä¶                 0.000195\n",
       "Length: 1288, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    Fqr = FreqRel('R')\n",
    "    Fqn = FreqRel('N')\n",
    "    Fqp = FreqRel('P')\n",
    "    Fqo = FreqRel('O')\n",
    "except: \n",
    "    pass\n",
    "\n",
    "FreqRel('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Neutro_set = set(FreqRel(0).index)\n",
    "Reacao_set = set(FreqRel('R').index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   P(N | palavras) = P(N) * P(cada_palavra | N)\n",
    "\n",
    "N√ÉO √â PRECISO DIVIDIR PELA PROBABILIDADE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_R = 1\n",
    "prob_tweet = 1\n",
    "dicR = {}\n",
    "for tweet in excel_treino['Teste']:\n",
    "    tweet = cleanup(tweet)\n",
    "    pal_tweet = tweet.split()\n",
    "    for palavra_teste in pal_tweet:\n",
    "        for palavra, freq in Fqr.items():\n",
    "            if palavra_teste in Fqr.items():\n",
    "                probabilidade = freq\n",
    "            else:\n",
    "                probabilidade = 1\n",
    "            prob_tweet = prob_tweet * freq\n",
    "    prob_tweet = prob_tweet * prob_cat('R')\n",
    "    dicR[tweet] = prob_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_N = 1\n",
    "prob_tweet = 1\n",
    "dicN = {}\n",
    "for tweet in excel_treino['Teste']:\n",
    "    tweet = cleanup(tweet)\n",
    "    pal_tweet = tweet.split()\n",
    "    for palavra_teste in pal_tweet:\n",
    "        for palavra, freq in Fqn.items():\n",
    "            print(palavra)\n",
    "            if palavra_teste in Fqn.items():\n",
    "                probabilidade = freq\n",
    "            else:\n",
    "                probabilidade = 1\n",
    "            prob_tweet = prob_tweet * freq\n",
    "    prob_tweet = prob_tweet * prob_cat('N')\n",
    "    dicN[tweet] = prob_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_P = 1\n",
    "prob_tweet = 1\n",
    "dicP = {}\n",
    "for tweet in excel_treino['Teste']:\n",
    "    tweet = cleanup(tweet)\n",
    "    pal_tweet = tweet.split()\n",
    "    for palavra_teste in pal_tweet:\n",
    "        for palavra, freq in Fqp.items():\n",
    "            if palavra_teste in Fqp.items():\n",
    "                probabilidade = freq\n",
    "            else:\n",
    "                probabilidade = 1\n",
    "            prob_tweet = prob_tweet * freq\n",
    "    prob_tweet = prob_tweet * prob_cat('P')\n",
    "    dicP[tweet] = prob_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_O = 1\n",
    "prob_tweet = 1\n",
    "dicO = {}\n",
    "for tweet in excel_treino['Teste']:\n",
    "    tweet = cleanup(tweet)\n",
    "    pal_tweet = tweet.split()\n",
    "    for palavra_teste in pal_tweet:\n",
    "        for palavra, freq in Fqo.items():\n",
    "            if palavra_teste in Fqo.items():\n",
    "                probabilidade = freq\n",
    "            else:\n",
    "                probabilidade = 1\n",
    "            prob_tweet = prob_tweet * freq\n",
    "    prob_tweet = prob_tweet * prob_cat('O')\n",
    "    dicO[tweet] = math.log(prob_tweet,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dicN['a coisa mais idiota de 13 reasons why foi colocar o zac e a cheryl nas fitas  botaram eles num n√≠vel de fdp igual aos outros desnecess√°rio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dicO['a coisa mais idiota de 13 reasons why foi colocar o zac e a cheryl nas fitas  botaram eles num n√≠vel de fdp igual aos outros desnecess√°rio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dicR['a coisa mais idiota de 13 reasons why foi colocar o zac e a cheryl nas fitas  botaram eles num n√≠vel de fdp igual aos outros desnecess√°rio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dicP['a coisa mais idiota de 13 reasons why foi colocar o zac e a cheryl nas fitas  botaram eles num n√≠vel de fdp igual aos outros desnecess√°rio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_classificados = []\n",
    "\n",
    "for tweet in excel_treino['Teste']:\n",
    "    tweet = cleanup(tweet)\n",
    "    pal_tweet = tweet.split()\n",
    "    maior = dicN[tweet]\n",
    "    if maior < dicP[tweet]:\n",
    "        maior = dicP\n",
    "        tweets_classificados.append('P')\n",
    "    elif maior < dicO[tweet]:\n",
    "        maior = dicO\n",
    "        tweets_classificados.append('O') \n",
    "    elif maior < dicR[tweet]:\n",
    "        maior = dicR\n",
    "        tweets_classificados.append('R')\n",
    "    else:\n",
    "        tweets_classificados.append('N')\n",
    "\n",
    "excel_treino['previsto'] = tweets_classificados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acur√°cia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 0\n",
    "falso_P = 0\n",
    "O = 0\n",
    "falso_O = 0\n",
    "R = 0\n",
    "falso_R = 0\n",
    "N = 0\n",
    "falso_N = 0\n",
    "\n",
    "\n",
    "total = len(excel_treino[\"Teste\"])\n",
    "\n",
    "for [e,i] in zip(excel_treino[\"Teste\"], excel_treino[\"previsto\"]):\n",
    "    if e == 1:\n",
    "        if i == 1:\n",
    "            P += 1\n",
    "        else: \n",
    "            falso_P += 1\n",
    "    if e == 2:            \n",
    "        if i == 2:\n",
    "            N +=1\n",
    "        else:\n",
    "            falso_N +=1\n",
    "    if e == 2:            \n",
    "        if i == 2:\n",
    "            O +=1\n",
    "        else:\n",
    "            falso_O +=1\n",
    "    if e == 2:            \n",
    "        if i == 2:\n",
    "            R +=1\n",
    "        else:\n",
    "            falso_R +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Positivos Verdadeiros: \", round((P/total)*100,2), \"%\")\n",
    "print(\"Positivos Falsos: \", round((falso_P/total)*100, 2), \"%\")\n",
    "print(\"Negativos Verdadeiros: \", round((N/total)*100,2), \"%\")\n",
    "print(\"Negativos Falsos: \", round((falso_N/total)*100, 2), \"%\")\n",
    "print(\"Neutros Verdadeiros: \", round((O/total)*100,2), \"%\")\n",
    "print(\"Neutros Falsos: \", round((falso_O/total)*100, 2), \"%\")\n",
    "print(\"Rea√ß√µes Verdadeiros: \", round((R/total)*100,2), \"%\")\n",
    "print(\"Rea√ß√µes Falsos: \", round((falso_R/total)*100, 2), \"%\")\n",
    "print(\"_\"*35)\n",
    "\n",
    "print(\"Acertos: \", round(((P/total)+(N/total)+(O/total)+(R/total))*100,2), \"%\")\n",
    "print(\"Erros: \", round(((falso_P/total)+(falso_N/total)+(falso_R/total)+(falso_O/total))*100,2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DASHBOARD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(tweets_classificados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from time import sleep\n",
    "# import pandas as pd\n",
    "\n",
    "# for e in range(3):\n",
    "#     !jupyter nbconvert --to notebook --execute Projeto2_layout.ipynb\n",
    "#     dashboard = pd.readExcel(\"13 Reasons Why novo.xlsx\")\n",
    "#     print(f\"dashoard: {dashoard}\")\n",
    "#     sleep(5)\n",
    "\n",
    "\n",
    "# excel_treino.to_excel('fill_auto1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "while True:\n",
    "    #getting new tweets\n",
    "    #Cria um objeto para a captura\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "    #Inicia a captura, para mais detalhes: ver a documenta√ß√£o do tweepy\n",
    "    i = 1\n",
    "    msgs = []\n",
    "    for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "        msgs.append(msg.text.lower())\n",
    "        i += 1\n",
    "        if i > n:\n",
    "            break\n",
    "\n",
    "    #Embaralhando as mensagens para reduzir um poss√≠vel vi√©s\n",
    "    lista = []\n",
    "    shuffle(msgs)\n",
    "\n",
    "    #Usando o set() para tirar os retweets\n",
    "    listaset = set(msgs)\n",
    "\n",
    "    #Adicionando o resultado do set() a uma lista para evitar o erro TypeError: 'set' object is not subscriptable\n",
    "    for value in listaset:\n",
    "        lista.append(value)\n",
    "    \n",
    "    #criando dataframe com novos tweets\n",
    "    df_teste = pd.DataFrame({'Teste' : pd.Series(lista)})\n",
    "    \n",
    "    #classifie new tweets\n",
    "    tweets_classificados = []\n",
    "\n",
    "    for tweet in excel_treino['Teste']:\n",
    "        tweet = cleanup(tweet)\n",
    "        pal_tweet = tweet.split()\n",
    "        maior = dicN[tweet]\n",
    "        if maior < dicP[tweet]:\n",
    "            maior = dicP\n",
    "            tweets_classificados.append('P')\n",
    "        elif maior < dicO[tweet]:\n",
    "            maior = dicO\n",
    "            tweets_classificados.append('O') \n",
    "        elif maior < dicR[tweet]:\n",
    "            maior = dicR\n",
    "            tweets_classificados.append('R')\n",
    "        else:\n",
    "            tweets_classificados.append('N')\n",
    "            \n",
    "    df_teste['Categorias'] = tweets_classificados\n",
    "    \n",
    "    #mostrar na dashboard:\n",
    "    \n",
    "\n",
    "    sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Por que n√£o se pode utilizar o pr√≥prio classificador para gerar mais amostras de treinamento?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Ao se utilizar o pr√≥prio classificador para gerar mais amostras de treinamento, o classificador acaba ficando \n",
    "    'viciado', ou seja, acaba-se por prejudicar os resultados obtidos, e eles acabam n√£o tendo uma qualidade boa.\n",
    "    Seria o contr√°rio de puxar mais tweets, que melhora a qualidade dos dados e dos resultados, por ter um espa√ßo \n",
    "    amostral muito maior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outras limpezas e tranforma√ß√µes:\n",
    "___\n",
    "    - Trocar v√≠rgu√ßas por espa√ßos\n",
    "    - Remover URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outros cen√°rios de Naive Bayes fora do contexto do projeto\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Previs√£o de Chuva\n",
    "    - Filtros de e-mail (Spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**\n",
    "\n",
    "https://towardsdatascience.com/naive-bayes-classifier-81d512f50a7c\n",
    "\n",
    "https://www.geeksforgeeks.org/naive-bayes-classifiers/\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probP = 0\n",
    "# probN = 0\n",
    "# probR = 0\n",
    "# probO = 0\n",
    "# i = 0\n",
    "# dic_catR = {}\n",
    "# dic_catP = {}\n",
    "# dic_catN = {}\n",
    "# dic_catO = {}\n",
    "\n",
    "\n",
    "# #Para cada tweet na planilha:\n",
    "# for tweet in excel_treino['Teste']:\n",
    "#     tweet = cleanup(tweet.lower())\n",
    "#     pal_tweet = tweet.split()\n",
    "#     #Para cada palavra de cada tweet:\n",
    "#     for palavra in pal_tweet:\n",
    "#         um = True\n",
    "#         for palavra1, frequencia in Fqr.items():\n",
    "#             if um == True:\n",
    "#                 #Seta a frquencia inicial de cada palavra para 1\n",
    "#                 dic_catR[tweet] = 1\n",
    "#             um = False\n",
    "#             # probabilidade total s√£o todas as probabilidades das palavras multiplicadas pela probabilidade de certa categoria\n",
    "#             dic_catR[tweet] = dic_catR[tweet] *  prob_cat('R') * frequencia\n",
    "                              \n",
    "#         for palavra1, frequencia in Fqn.items():\n",
    "#             if um == True:\n",
    "#                 dic_catN[tweet] = 1\n",
    "#             um = False\n",
    "#             dic_catN[tweet] = dic_catN[tweet] *  prob_cat('N') * frequencia\n",
    "            \n",
    "#         for palavra1, frequencia in Fqp.items():\n",
    "#             if um == True:\n",
    "#                 dic_catP[tweet] = 1\n",
    "#             um = False\n",
    "#             dic_catP[tweet] = dic_catP[tweet] *  prob_cat('P') * frequencia\n",
    "\n",
    "#         for palavra1, frequencia in Fqo.items():\n",
    "#             if um == True:\n",
    "#                 dic_catP[tweet] = 1\n",
    "#             um = False\n",
    "#             dic_catO[tweet] = dic_catP[tweet] *  prob_cat('O') * frequencia     \n",
    "\n",
    "#         #N√£o precisa dividir pela probabilidade do tweet pois cancelaria.\n",
    "    \n",
    "# # fazer contador pra ver qual √© a maior probabilidade, e adicionar em uma nova coluna do dataframe\n",
    "# #  DataFrame.insert(2, 'Predi√ß√£o', [lista com letra de cada linha], True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
