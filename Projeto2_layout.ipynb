{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Amanda Rosa do Carmo\n",
    "\n",
    "Nome: Beatriz Cabral\n",
    "\n",
    "Nome: Sophia Kerber Shigueoka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    punctuation = '[!\\-.:?;•,]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***@KerberSophie***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @KerberSophie\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantidade mínima de mensagens capturadas:\n",
    "Escolhemos 1480 a partir de um método empírico. Quando testamos com 1000 não conseguimos tweets suficientes, e chegamos\n",
    "a conclusão de que o problema era proveniente do set(), que diminuía a quantidade de tweets baixados. Assim, decidiu-se\n",
    "aumentar a quantidade de tweets para 1500, já que com 1000 ficaram falatando 360 tweets. Com 1500, ficamos com 20 tweets a mais.\n",
    "como eram somente 20 tweets, imaginamos que poucos deles seriam retweets, então tiramos exatamente 20 tweets dos 1500.\n",
    "Com 1480 tweets, conseguimos 399 tweets de teste, ou seja, faltou somente 1. não achamos que 1 tweets afetará tanto a base\n",
    "de dados, então decidimos manter os 1480."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = '13 Reasons Why'\n",
    "\n",
    "n = 1480\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 600\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 812\n"
     ]
    }
   ],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "    msgs.append(msg.text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "list = []\n",
    "shuffle(msgs)\n",
    "\n",
    "#Usando o set() para tirar os retweets\n",
    "listaset = set(msgs)\n",
    "\n",
    "#Adicionando o resultado do set() a uma lista para evitar o erro TypeError: 'set' object is not subscriptable\n",
    "for value in listaset:\n",
    "    list.append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Linhas abaixo foram comentadas uma vez que o conjunto de dados era o mesmo, mas o número de tweets foi alterado.\n",
    "\n",
    "# #Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "# if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "writer = pd.ExcelWriter('{0} novo.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "dft = pd.DataFrame({'Treinamento' : pd.Series(list[:t])})\n",
    "dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "dfc = pd.DataFrame({'Teste' : pd.Series(list[t:])})\n",
    "dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    punctuation = '[!\\-.:?;•,]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel = pd.read_excel('13 Reasons Why v2.xlsx', sheet_name='Treinamento')\n",
    "excel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_treino = pd.read_excel('13 Reasons Why v2.xlsx', sheet_name='Teste')\n",
    "excel_treino.rename(columns={'Unnamed: 1':'Clas_manual'}, inplace=True)\n",
    "excel_treino.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Função para limpar e criar tabela de frequências relativas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FreqRel(cat):\n",
    "    texto_completo = ' '.join(excel[excel.Categoria==cat].Treinamento)\n",
    "    semhttp = re.sub(r'http\\S+', '', texto_completo)\n",
    "    text_limpo = cleanup(semhttp)\n",
    "    rel = text_limpo.split()\n",
    "    freq_rel = pd.Series(rel).value_counts(True)\n",
    "    return freq_rel\n",
    "\n",
    "FreqRel('P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Estas funções dividem a função anterior\n",
    "def Limpa(texto):\n",
    "    semhttp = re.sub(r'http\\S+', '', texto)\n",
    "    text_limpo = cleanup(semhttp)\n",
    "    rel = text_limpo.split()\n",
    "    return(rel)\n",
    "\n",
    "def FreqRel(Limpa):\n",
    "    freq_rel = pd.Series(Limpa).value_counts(True)\n",
    "    return freq_rel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Descobrindo P(N), P(R), P(P) e P(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_1 = ' '.join(excel[excel.Categoria=='O'].Treinamento)\n",
    "texto_2 = ' '.join(excel[excel.Categoria=='R'].Treinamento)\n",
    "texto_3 = ' '.join(excel[excel.Categoria=='P'].Treinamento)\n",
    "texto_4 = ' '.join(excel[excel.Categoria=='N'].Treinamento)\n",
    "\n",
    "texto_1 = Limpa(texto_1)\n",
    "texto_2 = Limpa(texto_2)\n",
    "texto_3 = Limpa(texto_3)\n",
    "texto_4 = Limpa(texto_4)\n",
    "\n",
    "#juntando todos os textos\n",
    "texto_enorme = texto_1 + texto_2 + texto_3 + texto_4\n",
    "set(texto_enorme)\n",
    "dic_global = 0\n",
    "for palavra in texto_enorme:\n",
    "        dic_global+=1\n",
    "    \n",
    "print('Todas as palavras somadas:')\n",
    "print(dic_global)\n",
    "\n",
    "def prob_cat(cat):\n",
    "    palavras = 0\n",
    "    texto_completo = ' '.join(excel[excel.Categoria==cat].Treinamento)\n",
    "    texto_completo.replace('•', '')\n",
    "    semhttp = re.sub(r'http\\S+', '', texto_completo)\n",
    "    text_limpo = cleanup(semhttp)\n",
    "    rel = text_limpo.split()\n",
    "    set(rel)\n",
    "    # Para verificar se o código era coerente, imprimimos o total de palavras de cada categoria\n",
    "    for palavra in rel:\n",
    "        palavras += 1\n",
    "    prob_final = palavras/dic_global\n",
    "    return prob_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Probabilidade da Categoria 'Neutro'\")\n",
    "print(prob_cat('O'))\n",
    "print('')\n",
    "print(\"Probabilidade da Categoria 'Negativo'\")\n",
    "print(prob_cat('N'))\n",
    "print('')\n",
    "print(\"Probabilidade da Categoria 'Positivo'\")\n",
    "print(prob_cat('P'))\n",
    "print('')\n",
    "print(\"Probabilidade da Categoria 'Reação'\")\n",
    "print(prob_cat('R'))\n",
    "\n",
    "\n",
    "\n",
    "print('')\n",
    "print(\"Probabilidade Total (se tudo der certo, deve ser 1)\")\n",
    "print(prob_cat('O') + prob_cat('N') + prob_cat('P') + prob_cat('R'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    Fqr = FreqRel('R')\n",
    "    Fqn = FreqRel('N')\n",
    "    Fqp = FreqRel('P')\n",
    "    Fqo = FreqRel('O')\n",
    "except: \n",
    "    pass\n",
    "\n",
    "for palavra, frequencia in Fqr.items():\n",
    "    print(palavra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Neutro_set = set(FreqRel(0).index)\n",
    "Reacao_set = set(FreqRel('R').index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   P(N | palavras) = P(N) * P(cada_palavra | N)\n",
    "\n",
    "NÃO É PRECISO DIVIDIR PELA PROBABILIDADE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probP = 0\n",
    "# probN = 0\n",
    "# probR = 0\n",
    "# probO = 0\n",
    "# i = 0\n",
    "# dic_catR = {}\n",
    "# dic_catP = {}\n",
    "# dic_catN = {}\n",
    "# dic_catO = {}\n",
    "\n",
    "\n",
    "# #Para cada tweet na planilha:\n",
    "# for tweet in excel_treino['Teste']:\n",
    "#     tweet = cleanup(tweet.lower())\n",
    "#     pal_tweet = tweet.split()\n",
    "#     #Para cada palavra de cada tweet:\n",
    "#     for palavra in pal_tweet:\n",
    "#         um = True\n",
    "#         for palavra1, frequencia in Fqr.items():\n",
    "#             if um == True:\n",
    "#                 #Seta a frquencia inicial de cada palavra para 1\n",
    "#                 dic_catR[tweet] = 1\n",
    "#             um = False\n",
    "#             # probabilidade total são todas as probabilidades das palavras multiplicadas pela probabilidade de certa categoria\n",
    "#             dic_catR[tweet] = dic_catR[tweet] *  prob_cat('R') * frequencia\n",
    "                              \n",
    "#         for palavra1, frequencia in Fqn.items():\n",
    "#             if um == True:\n",
    "#                 dic_catN[tweet] = 1\n",
    "#             um = False\n",
    "#             dic_catN[tweet] = dic_catN[tweet] *  prob_cat('N') * frequencia\n",
    "            \n",
    "#         for palavra1, frequencia in Fqp.items():\n",
    "#             if um == True:\n",
    "#                 dic_catP[tweet] = 1\n",
    "#             um = False\n",
    "#             dic_catP[tweet] = dic_catP[tweet] *  prob_cat('P') * frequencia\n",
    "\n",
    "#         for palavra1, frequencia in Fqo.items():\n",
    "#             if um == True:\n",
    "#                 dic_catP[tweet] = 1\n",
    "#             um = False\n",
    "#             dic_catO[tweet] = dic_catP[tweet] *  prob_cat('O') * frequencia     \n",
    "\n",
    "#         #Não precisa dividir pela probabilidade do tweet pois cancelaria.\n",
    "    \n",
    "# # fazer contador pra ver qual é a maior probabilidade, e adicionar em uma nova coluna do dataframe\n",
    "# #  DataFrame.insert(2, 'Predição', [lista com letra de cada linha], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_R = 1\n",
    "prob_tweet = 1\n",
    "dicR = {}\n",
    "for tweet in excel_treino['Teste']:\n",
    "    tweet = cleanup(tweet)\n",
    "    pal_tweet = tweet.split()\n",
    "    for palavra_teste in pal_tweet:\n",
    "        for palavra, freq in Fqr.items():\n",
    "            if palavra_teste in Fqr.items():\n",
    "                probabilidade = freq\n",
    "            else:\n",
    "                probabilidade = 1\n",
    "            prob_tweet = prob_tweet * freq\n",
    "    prob_tweet = prob_tweet * prob_cat('R')\n",
    "    dicR[tweet] = prob_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_N = 1\n",
    "prob_tweet = 1\n",
    "dicN = {}\n",
    "for tweet in excel_treino['Teste']:\n",
    "    tweet = cleanup(tweet)\n",
    "    pal_tweet = tweet.split()\n",
    "    for palavra_teste in pal_tweet:\n",
    "        for palavra, freq in Fqn.items():\n",
    "            if palavra_teste in Fqn.items():\n",
    "                probabilidade = freq\n",
    "            else:\n",
    "                probabilidade = 1\n",
    "            prob_tweet = prob_tweet * freq\n",
    "    prob_tweet = prob_tweet * prob_cat('N')\n",
    "    dicN[tweet] = prob_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_P = 1\n",
    "prob_tweet = 1\n",
    "dicP = {}\n",
    "for tweet in excel_treino['Teste']:\n",
    "    tweet = cleanup(tweet)\n",
    "    pal_tweet = tweet.split()\n",
    "    for palavra_teste in pal_tweet:\n",
    "        for palavra, freq in Fqp.items():\n",
    "            if palavra_teste in Fqp.items():\n",
    "                probabilidade = freq\n",
    "            else:\n",
    "                probabilidade = 1\n",
    "            prob_tweet = prob_tweet * freq\n",
    "    prob_tweet = prob_tweet * prob_cat('P')\n",
    "    dicP[tweet] = prob_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_O = 1\n",
    "prob_tweet = 1\n",
    "dicO = {}\n",
    "for tweet in excel_treino['Teste']:\n",
    "    tweet = cleanup(tweet)\n",
    "    pal_tweet = tweet.split()\n",
    "    for palavra_teste in pal_tweet:\n",
    "        for palavra, freq in Fqo.items():\n",
    "            if palavra_teste in Fqo.items():\n",
    "                probabilidade = freq\n",
    "            else:\n",
    "                probabilidade = 1\n",
    "            prob_tweet = prob_tweet * freq\n",
    "    prob_tweet = prob_tweet * prob_cat('O')\n",
    "    dicO[tweet] = math.log(prob_tweet,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dicN['a coisa mais idiota de 13 reasons why foi colocar o zac e a cheryl nas fitas  botaram eles num nível de fdp igual aos outros desnecessário'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dicO['a coisa mais idiota de 13 reasons why foi colocar o zac e a cheryl nas fitas  botaram eles num nível de fdp igual aos outros desnecessário'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dicR['a coisa mais idiota de 13 reasons why foi colocar o zac e a cheryl nas fitas  botaram eles num nível de fdp igual aos outros desnecessário'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dicP['a coisa mais idiota de 13 reasons why foi colocar o zac e a cheryl nas fitas  botaram eles num nível de fdp igual aos outros desnecessário'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_classificados = []\n",
    "\n",
    "for tweet in excel_treino['Teste']:\n",
    "    tweet = cleanup(tweet)\n",
    "    pal_tweet = tweet.split()\n",
    "    maior = dicN[tweet]\n",
    "    if maior < dicP[tweet]:\n",
    "        maior = dicP\n",
    "        tweets_classificados.append('P')\n",
    "    elif maior < dicO[tweet]:\n",
    "        maior = dicO\n",
    "        tweets_classificados.append('O') \n",
    "    elif maior < dicR[tweet]:\n",
    "        maior = dicR\n",
    "        tweets_classificados.append('R')\n",
    "    else:\n",
    "        tweets_classificados.append('N')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DASHBOARD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(tweets_classificados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from time import sleep\n",
    "# import pandas as pd\n",
    "\n",
    "# for e in range(3):\n",
    "#     !jupyter nbconvert --to notebook --execute Projeto2_layout.ipynb\n",
    "#     dashboard = pd.readExcel(\"13 Reasons Why novo.xlsx\")\n",
    "#     print(f\"dashoard: {dashoard}\")\n",
    "#     sleep(5)\n",
    "\n",
    "\n",
    "# excel_treino.to_excel('fill_auto1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweepy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6363c2bc1483>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#getting new tweets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#Cria um objeto para a captura\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mapi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAPI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwait_on_rate_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwait_on_rate_limit_notify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#Inicia a captura, para mais detalhes: ver a documentação do tweepy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tweepy' is not defined"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "while True:\n",
    "    #getting new tweets\n",
    "    #Cria um objeto para a captura\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "    #Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "    i = 1\n",
    "    msgs = []\n",
    "    for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "        msgs.append(msg.text.lower())\n",
    "        i += 1\n",
    "        if i > n:\n",
    "            break\n",
    "\n",
    "    #Embaralhando as mensagens para reduzir um possível viés\n",
    "    lista = []\n",
    "    shuffle(msgs)\n",
    "\n",
    "    #Usando o set() para tirar os retweets\n",
    "    listaset = set(msgs)\n",
    "\n",
    "    #Adicionando o resultado do set() a uma lista para evitar o erro TypeError: 'set' object is not subscriptable\n",
    "    for value in listaset:\n",
    "        lista.append(value)\n",
    "    \n",
    "    #criando dataframe com novos tweets\n",
    "    df_teste = pd.DataFrame({'Teste' : pd.Series(lista)})\n",
    "    \n",
    "    #classifie new tweets\n",
    "    tweets_classificados = []\n",
    "\n",
    "    for tweet in excel_treino['Teste']:\n",
    "        tweet = cleanup(tweet)\n",
    "        pal_tweet = tweet.split()\n",
    "        maior = dicN[tweet]\n",
    "        if maior < dicP[tweet]:\n",
    "            maior = dicP\n",
    "            tweets_classificados.append('P')\n",
    "        elif maior < dicO[tweet]:\n",
    "            maior = dicO\n",
    "            tweets_classificados.append('O') \n",
    "        elif maior < dicR[tweet]:\n",
    "            maior = dicR\n",
    "            tweets_classificados.append('R')\n",
    "        else:\n",
    "            tweets_classificados.append('N')\n",
    "            \n",
    "    df_teste['Categorias'] = tweets_classificados\n",
    "    \n",
    "    #mostrar na dashboard:\n",
    "    \n",
    "\n",
    "    sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Por que não se pode utilizar o próprio classificador para gerar mais amostras de treinamento?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Ao se utilizar o próprio classificador para gerar mais amostras de treinamento, o classificador acaba ficando \n",
    "    'viciado', ou seja, acaba-se por prejudicar os resultados obtidos, e eles acabam não tendo uma qualidade boa.\n",
    "    Seria o contrário de puxar mais tweets, que melhora a qualidade dos dados e dos resultados, por ter um espaço \n",
    "    amostral muito maior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outras limpezas e tranformações:\n",
    "___\n",
    "    - Trocar vírguças por espaços\n",
    "    - Remover URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outros cenários de Naive Bayes fora do contexto do projeto\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Previsão de Chuva\n",
    "    - Filtros de e-mail (Spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**\n",
    "\n",
    "https://towardsdatascience.com/naive-bayes-classifier-81d512f50a7c\n",
    "\n",
    "https://www.geeksforgeeks.org/naive-bayes-classifiers/\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
